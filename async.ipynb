{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80fabe8",
   "metadata": {},
   "source": [
    "#### threading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591a149",
   "metadata": {},
   "source": [
    "##### Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Event, Thread\n",
    "import time\n",
    "\n",
    "\n",
    "def countdown(number: int, event: Event) -> None:\n",
    "    print(f\"Countdown from {number} started\")\n",
    "    for index in range(number):\n",
    "        print(f\"Countdown: {number - index}\")\n",
    "        time.sleep(1)\n",
    "    print(f\"Countdown from {number} finished\")\n",
    "    event.set()\n",
    "\n",
    "\n",
    "event = Event()\n",
    "\n",
    "thread = Thread(target=countdown, args=(5, event))\n",
    "thread.start()\n",
    "\n",
    "event.wait()\n",
    "print(\"Countdown completed, main thread continues\")\n",
    "\n",
    "event.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4747d0",
   "metadata": {},
   "source": [
    "##### Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Condition, Thread\n",
    "import time\n",
    "\n",
    "\n",
    "def produce(condition: Condition, items: list) -> None:\n",
    "    for item in range(5):\n",
    "        with condition:  # ✅ 每次生产时短暂持有锁\n",
    "            items.append(item)\n",
    "            print(f\"Produced {item}\")\n",
    "            condition.notify()\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "def consume(condition: Condition, items: list) -> None:\n",
    "    while True:  # ✅ 持续消费\n",
    "        with condition:\n",
    "            while not items:\n",
    "                print(\"等待生产...\")\n",
    "                condition.wait()\n",
    "            item = items.pop(0)\n",
    "            print(f\"Consumed {item}\")\n",
    "\n",
    "\n",
    "items = []\n",
    "condition = Condition()\n",
    "\n",
    "producer_thread = Thread(target=produce, args=(condition, items))\n",
    "consumer_thread = Thread(target=consume, args=(condition, items))\n",
    "\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "\n",
    "producer_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a7eda4",
   "metadata": {},
   "source": [
    "##### Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def process(source: Any, lock: Lock) -> None:\n",
    "    with lock:\n",
    "        print(f\"Processing {source}\")\n",
    "        time.sleep(5)\n",
    "        print(f\"Finished processing {source}\")\n",
    "\n",
    "\n",
    "def get(source: Any, lock: Lock) -> None:\n",
    "    while True:\n",
    "        if lock.locked():\n",
    "            print(f\"Wait {source}\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(f\"Get {source}\")\n",
    "            break\n",
    "\n",
    "\n",
    "lock = Lock()\n",
    "source = \"Data Source\"\n",
    "process_thread = Thread(target=process, args=(source, lock))\n",
    "get_thread = Thread(target=get, args=(source, lock))\n",
    "process_thread.start()\n",
    "get_thread.start()\n",
    "process_thread.join()\n",
    "get_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996fff3",
   "metadata": {},
   "source": [
    "##### RLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56512924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import RLock, Thread\n",
    "import time\n",
    "\n",
    "\n",
    "def process_data(source: str, lock: RLock) -> None:\n",
    "    with lock:  # 第一次获取锁\n",
    "        print(f\"🔒 [Process] 开始处理 {source}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        # 嵌套调用需要同一把锁的函数\n",
    "        save_result(source, lock)  # ⭐ 这里需要再次获取锁\n",
    "        print(f\"✅ [Process] 完成处理 {source}\")\n",
    "\n",
    "\n",
    "def save_result(source: str, lock: RLock) -> None:\n",
    "    with lock:  # 第二次获取锁（RLock 允许同一线程重复获取）\n",
    "        print(f\"💾 [Save] 保存 {source} 的结果\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "# 使用 RLock 代替 Lock\n",
    "lock = RLock()\n",
    "source = \"关键数据\"\n",
    "\n",
    "# 启动线程\n",
    "t = Thread(target=process_data, args=(source, lock))\n",
    "t.start()\n",
    "t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d9386",
   "metadata": {},
   "source": [
    "##### Lock/RLock\n",
    "\n",
    "|特性|`Lock` (普通锁)|`RLock` (可重入锁)|\n",
    "|---|---|---|\n",
    "|**重入性**|❌ 同一线程无法重复获取锁|✅ 同一线程可多次获取锁|\n",
    "|**锁的持有者**|不记录持有线程|记录持有线程和递归深度|\n",
    "|**释放机制**|必须由获取锁的线程释放|必须由获取锁的线程释放，且释放次数需匹配|\n",
    "|**性能**|更高（简单实现）|略低（需要维护递归计数）|\n",
    "|**适用场景**|简单的互斥操作|嵌套/递归调用的代码|\n",
    "\n",
    "##### 安全使用锁\n",
    "\n",
    "- 所有线程获取锁的顺序要一致\n",
    "- 使用超时机制 `acquire(timeout=3)`\n",
    "\n",
    "##### 同时按照顺序获取多个锁的简洁写法\n",
    "\n",
    "```python\n",
    "with lock_a, lock_b:\n",
    "    # 等同于 with lock_a: with lock_b:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d7a12",
   "metadata": {},
   "source": [
    "##### Barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "# 定义阶段数量（每个阶段一个 Barrier）\n",
    "phase1_barrier = threading.Barrier(\n",
    "    parties=3, action=lambda: print(\"\\n== 所有线程完成数据加载，开始清洗 ==\\n\")\n",
    ")\n",
    "phase2_barrier = threading.Barrier(\n",
    "    parties=3, action=lambda: print(\"\\n== 所有线程完成数据清洗，开始分析 ==\\n\")\n",
    ")\n",
    "\n",
    "\n",
    "def data_processing(thread_id):\n",
    "    # 第一阶段：数据加载\n",
    "    load_time = random.uniform(2, 4)\n",
    "    time.sleep(load_time)\n",
    "    print(f\"线程 {thread_id} 数据加载完成（耗时 {load_time:.1f}s）\")\n",
    "\n",
    "    phase1_barrier.wait()  # 等待所有线程完成加载\n",
    "\n",
    "    # 第二阶段：数据清洗\n",
    "    clean_time = random.uniform(2, 4)\n",
    "    time.sleep(clean_time)\n",
    "    print(f\"线程 {thread_id} 数据清洗完成（耗时 {clean_time:.1f}s）\")\n",
    "\n",
    "    phase2_barrier.wait()  # 等待所有线程完成清洗\n",
    "\n",
    "    # 第三阶段：数据分析\n",
    "    analysis_time = random.uniform(2, 4)\n",
    "    time.sleep(analysis_time)\n",
    "    print(f\"线程 {thread_id} 数据分析完成（耗时 {analysis_time:.1f}s）\")\n",
    "\n",
    "\n",
    "# 创建 3 个线程\n",
    "threads = []\n",
    "for i in range(1, 4):\n",
    "    t = threading.Thread(target=data_processing, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# 等待所有线程完成\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"所有处理阶段完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892279f9",
   "metadata": {},
   "source": [
    "##### Semaphore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 初始化一个信号量，允许最多 3 个线程同时访问\n",
    "semaphore = threading.Semaphore(3)\n",
    "\n",
    "\n",
    "def access_resource(thread_id):\n",
    "    with semaphore:  # 请求信号量，如果信号量计数大于 0，线程才能继续\n",
    "        print(f\"⌛️ Thread-{thread_id} has acquired the resource.\")\n",
    "        time.sleep(random.uniform(2, 4))  # 模拟线程使用资源的时间\n",
    "        print(f\"✅ Thread-{thread_id} has released the resource.\")\n",
    "\n",
    "\n",
    "# 创建并启动 5 个线程\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=access_resource, args=(i,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# 等待所有线程完成\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"All threads have finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5344667",
   "metadata": {},
   "source": [
    "##### BoundedSemaphore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "bounded_semaphore = threading.BoundedSemaphore(3)\n",
    "\n",
    "try:\n",
    "    bounded_semaphore.release()\n",
    "except ValueError as e:\n",
    "    print(f\"Semaphore released failed, {e}\")\n",
    "\n",
    "try:\n",
    "    bounded_semaphore.acquire(timeout=0.1)\n",
    "    bounded_semaphore.release()\n",
    "    print(\"Semaphore released successfully\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6e802",
   "metadata": {},
   "source": [
    "##### Semaphore/BoundedSeamphore\n",
    "\n",
    "|特性|`Semaphore`|`BoundedSemaphore`|\n",
    "|---|---|---|\n",
    "|**最大信号量数**|可以随意增加释放次数，不会抛出异常|不允许释放次数超过初始化的信号量数|\n",
    "|**`release()` 的限制**|没有限制，可以超过初始计数|`release()` 次数要与 `acquire()` 一致|\n",
    "|**适用场景**|适合对释放次数没有严格要求的情况|适合需要严格控制释放次数的场景，如防止程序中释放信号量过多导致的问题|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558a8a2",
   "metadata": {},
   "source": [
    "##### Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef73062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def do_something(name: Any, queue: list):\n",
    "    queue.append(name)\n",
    "\n",
    "\n",
    "pool = list()\n",
    "timer = threading.Timer(2, do_something, args=(\"Alice\", pool))\n",
    "timer.start()\n",
    "\n",
    "while not pool:\n",
    "    print(\"Waiting for Alice...\")\n",
    "    time.sleep(1)\n",
    "else:\n",
    "    print(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f79de",
   "metadata": {},
   "source": [
    "#### communication tools\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfdd19",
   "metadata": {},
   "source": [
    "##### Queue\n",
    "\n",
    "- `queue.Queue` 普通的 FIFO 队列\n",
    "- `queue.LifoQueue` LIFO 队列（后进先出）\n",
    "- `queue.PriorityQueue` 带优先级的队列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "\n",
    "def produce(production: queue.LifoQueue):\n",
    "    for goods in range(5):\n",
    "        time.sleep(1)\n",
    "        print(f\"生产者生产了数据: {goods}\")\n",
    "        production.put(goods)\n",
    "\n",
    "\n",
    "def consume(production: queue.Queue):\n",
    "    while True:\n",
    "        item = production.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        print(f\"消费者消费了数据: {item}\")\n",
    "        production.task_done()\n",
    "\n",
    "\n",
    "production = queue.LifoQueue()\n",
    "producer_thread = threading.Thread(target=produce, args=(production,))\n",
    "producer_thread.start()\n",
    "consumer_thread = threading.Thread(target=consume, args=(production,))\n",
    "consumer_thread.start()\n",
    "producer_thread.join()\n",
    "production.put(None)\n",
    "consumer_thread.join()\n",
    "print(\"所有线程结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a02e8",
   "metadata": {},
   "source": [
    "##### threading.local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 创建一个线程局部存储\n",
    "local_data = threading.local()\n",
    "\n",
    "\n",
    "def thread_task(thread_id):\n",
    "    # 每个线程有自己的局部数据\n",
    "    local_data.value = thread_id\n",
    "    time.sleep(random.randrange(1, 3))\n",
    "    print(f\"线程 {thread_id} 的局部数据: {local_data.value}\")\n",
    "\n",
    "\n",
    "# 创建多个线程并启动\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=thread_task, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# 等待所有线程结束\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"所有线程结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ae65f",
   "metadata": {},
   "source": [
    "#### multiprocessing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314cf4c",
   "metadata": {},
   "source": [
    "##### Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def worker(pipe):\n",
    "    # 进程的工作函数\n",
    "    data = pipe.recv()\n",
    "    print(f\"Received: {data}\")\n",
    "    pipe.send(f\"Processed {data}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 创建管道\n",
    "    parent, child = multiprocessing.Pipe()\n",
    "\n",
    "    # 启动进程\n",
    "    process = multiprocessing.Process(target=worker, args=(child,))\n",
    "    process.start()\n",
    "\n",
    "    # 向进程发送数据，此时子进程会阻塞在 recv() 处\n",
    "    parent.send(\"Data from main process\")\n",
    "\n",
    "    # 获取进程处理后的数据\n",
    "    print(f\"Received from worker: {parent.recv()}\")\n",
    "\n",
    "    # 等待进程完成\n",
    "    process.join()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 显式设置启动方式\n",
    "    multiprocessing.set_start_method(\"spawn\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586dcea9",
   "metadata": {},
   "source": [
    "##### Manager\n",
    "\n",
    "- `Manager` 下的数据结构是进程间共享的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def work(share_list, item):\n",
    "    time.sleep(random.randint(1, 3))\n",
    "    print(f\"I am {item} process, Current list: {share_list}\")\n",
    "    share_list.append(item)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a list that can be shared between processes\n",
    "    share_list = multiprocessing.Manager().list()\n",
    "\n",
    "    # Create a list of processes\n",
    "    processes = []\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=work, args=(share_list, i))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all processes to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(f\"Final list: {share_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f325d",
   "metadata": {},
   "source": [
    "##### Pool\n",
    "\n",
    "| 方法                 | 描述                                   | 返回值                     | 是否异步执行 |\n",
    "| ------------------ | ------------------------------------ | ----------------------- | ------ |\n",
    "| `apply()`          | 同步执行单个任务，返回结果                        | 任务的结果                   | ❌      |\n",
    "| `apply_async()`    | 异步执行单个任务，返回 `AsyncResult` 对象         | `AsyncResult` 对象，稍后获取结果 | ✅      |\n",
    "| `imap()`           | 并行处理可迭代对象，按顺序返回结果                    | 迭代器                  | ❌      |\n",
    "| `imap_unordered()` | 并行处理可迭代对象，返回无序结果                     | 迭代器                  | ❌      |\n",
    "| `join()`           | 等待所有进程完成（通常在调用 `close()` 后使用）        | 无                       | ❌      |\n",
    "| `map()`            | 并行处理可迭代对象，返回结果（按顺序返回）                | 列表               | ❌      |\n",
    "| `map_async()`      | 异步执行 `map()`，返回 `AsyncResult` 对象     | `AsyncResult` 对象，稍后获取结果 | ✅      |\n",
    "| `Process()`        | 直接创建进程并启动，适用于单独的进程任务执行               | 无                       | ✅      |\n",
    "| `starmap()`        | 并行处理需要多个参数的任务，解包元组参数                 | 列表               | ❌      |\n",
    "| `starmap_async()`  | 异步执行 `starmap()`，返回 `AsyncResult` 对象 | `AsyncResult` 对象，稍后获取结果 | ✅      |\n",
    "| `terminate()`      | 立即终止所有进程，强制结束任务                      | 无                       | ✅      |\n",
    "| `close()`          | 关闭池，不再接受新的任务                         | 无                       | ❌      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def square(x):\n",
    "    time.sleep(1)\n",
    "    return x * x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "\n",
    "    numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # 使用 imap_unordered 处理任务（不保证顺序）\n",
    "    result = pool.imap_unordered(square, numbers)\n",
    "\n",
    "    for res in result:\n",
    "        print(res)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c40be7",
   "metadata": {},
   "source": [
    "##### Value/RawValue\n",
    "\n",
    "|属性|`Value`|`RawValue`|\n",
    "|---|---|---|\n",
    "|**类型检查**|提供类型检查，保证数据类型一致|不进行类型检查，存储原始字节数据|\n",
    "|**内存管理**|自动加锁，适合常规数据类型（如整数、浮动等）|无类型管理，更底层，适合存储原始数据|\n",
    "|**使用场景**|适用于共享基本数据类型，如整数、浮动数等|适用于需要存储原始数据或更复杂结构的场景|\n",
    "|**性能**|稍慢（有类型检查）|更快（无类型检查），但需要自己管理数据存储和格式|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def increment(shared_value):\n",
    "    for _ in range(5):\n",
    "        time.sleep(1)\n",
    "        with shared_value.get_lock():\n",
    "            shared_value.value += 1\n",
    "            print(f\"Shared value in process: {shared_value.value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 禁用自动锁，需要自行保证进程安全\n",
    "    shared_value = multiprocessing.Value(\"i\", 0, lock=False)\n",
    "\n",
    "    processes = []\n",
    "    for _ in range(3):\n",
    "        p = multiprocessing.Process(target=increment, args=(shared_value,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(f\"Final shared value: {shared_value.value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae32579",
   "metadata": {},
   "source": [
    "##### Array/RawArray\n",
    "\n",
    "|属性|`Array`|`RawArray`|\n",
    "|---|---|---|\n",
    "|**类型检查**|自动提供类型检查，确保数据类型一致|不进行类型检查，直接存储原始字节数据|\n",
    "|**同步机制**|自动加锁，保证线程安全|不提供自动同步，需要手动加锁|\n",
    "|**适用场景**|适用于需要线程安全访问的共享数组|适用于需要低级控制和不需要同步机制的共享数据|\n",
    "|**性能**|稍慢（因为有同步机制）|更快（因为没有同步机制，适合对数据进行更精细的控制）|\n",
    "\n",
    "##### 自动锁\n",
    "\n",
    "- 复合语句依旧需要加锁\n",
    "- 多个变量同步也需要加锁\n",
    "\n",
    "##### 加锁场景\n",
    "```python\n",
    "# 非原子操作\n",
    "with v.get_lock():\n",
    "    if v.value > 10:\n",
    "        v.value -= 5\n",
    "\n",
    "# 多个共享变量\n",
    "with v1.get_lock(), v2.get_lock():\n",
    "    v1.value += v2.value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586162ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def increment(shared_array, index):\n",
    "    for _ in range(5):\n",
    "        time.sleep(1)\n",
    "        shared_array[index] += 1\n",
    "        print(f\"Shared array[{index}] in process: {shared_array[index]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 启用自动锁\n",
    "    shared_array = multiprocessing.Array(\"i\", [0, 0, 0], lock=True)\n",
    "\n",
    "    processes = []\n",
    "    for i in range(3):\n",
    "        p = multiprocessing.Process(target=increment, args=(shared_array, i))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(f\"Final shared array: {shared_array[:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd76bb",
   "metadata": {},
   "source": [
    "##### SimpleQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cded91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def producer(q):\n",
    "    for i in range(5):\n",
    "        time.sleep(1)\n",
    "        print(f\"Producer putting item {i} into queue\")\n",
    "        q.put(i)  # 向队列中放入数据\n",
    "\n",
    "\n",
    "def consumer(q):\n",
    "    for _ in range(5):\n",
    "        item = q.get()  # 从队列中取出数据\n",
    "        print(f\"Consumer got item {item} from queue\")\n",
    "        time.sleep(2)  # 模拟处理时间\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建一个 SimpleQueue 对象\n",
    "    q = multiprocessing.SimpleQueue()\n",
    "\n",
    "    # 创建并启动生产者进程和消费者进程\n",
    "    producer_process = multiprocessing.Process(target=producer, args=(q,))\n",
    "    consumer_process = multiprocessing.Process(target=consumer, args=(q,))\n",
    "\n",
    "    producer_process.start()\n",
    "    consumer_process.start()\n",
    "\n",
    "    producer_process.join()  # 等待生产者进程完成\n",
    "    consumer_process.join()  # 等待消费者进程完成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e742c6",
   "metadata": {},
   "source": [
    "##### Other\n",
    "\n",
    "- `multiprocessing.Barrier()`\n",
    "- `multiprocessing.Condition()`\n",
    "- `multiprocessing.Semaphore()`\n",
    "- `multiprocessing.BoundedSemaphore()`\n",
    "- `multiprocessing.Lock()`\n",
    "- `multiprocessing.RLock()`\n",
    "- `multiprocessing.Event()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707ee0c",
   "metadata": {},
   "source": [
    "#### concurrent.futures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd5a4e",
   "metadata": {},
   "source": [
    "##### ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "def fetch_data(x):\n",
    "    print(f\"Fetching data for {x}...\")\n",
    "    time.sleep(2)\n",
    "    return f\"Data {x}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        result = list(executor.map(fetch_data, [1, 2, 3, 4, 5]))\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9d1f5",
   "metadata": {},
   "source": [
    "##### ProcessPoolExecutor\n",
    "\n",
    "- 等效于 `multiprocessing.Pool()`\n",
    "- API 更加简洁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "def compute_square(x):\n",
    "    print(f\"Computing square for {x}...\")\n",
    "    time.sleep(2)\n",
    "    return x * x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        result = list(executor.map(compute_square, [1, 2, 3, 4, 5]))\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928358a",
   "metadata": {},
   "source": [
    "#### asyncio\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d60108",
   "metadata": {},
   "source": [
    "##### async/await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "# 定义一个简单的协程任务\n",
    "async def hello_world():\n",
    "    print(\"Hello\")\n",
    "    await asyncio.sleep(1)  # 模拟一个 I/O 操作\n",
    "    print(\"World\")\n",
    "\n",
    "\n",
    "# 运行事件循环\n",
    "async def main():\n",
    "    await hello_world()\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def fetch_data(x):\n",
    "    print(f\"Fetching data for {x}...\")\n",
    "    await asyncio.sleep(2)\n",
    "    return f\"Data {x}\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    tasks = [fetch_data(i) for i in range(5)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(results)\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def task(name, delay):\n",
    "    if delay == 2:\n",
    "        raise ValueError(f\"Task {name} encountered an error!\")\n",
    "    await asyncio.sleep(delay)\n",
    "    return f\"Task {name} completed\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    tasks = [task(\"A\", 1), task(\"B\", 2), task(\"C\", 3)]\n",
    "    # 使用 gather 时捕获异常\n",
    "    try:\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        print(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58397c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def periodic_task():\n",
    "    while True:\n",
    "        print(\"Task executed\")\n",
    "        await asyncio.sleep(3)  # 每隔 3 秒执行一次\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # 创建周期性任务\n",
    "    task = asyncio.create_task(periodic_task())\n",
    "    # 运行 10 秒后停止\n",
    "    await asyncio.sleep(10)\n",
    "    task.cancel()  # 取消周期性任务\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114638dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "async def fetch(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    urls = [\"https://www.example.com\", \"https://www.python.org\"]\n",
    "    tasks = [fetch(url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    for result in results:\n",
    "        print(f\"Fetched data: {result}...\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8644af7",
   "metadata": {},
   "source": [
    "##### Event loop\n",
    "\n",
    "- 事件循环就是一个在后台不停运行、等待和执行任务的循环\n",
    "- 事件循环是其核心机制，它负责调度和管理\n",
    "- 它使得程序能够在执行某个任务时，不会被阻塞，能够同时执行其他任务\n",
    "- `run_forever()` 必须手动停止\n",
    "- `call_later()` 的回调函数不能是协程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54efe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def task(name, delay):\n",
    "    print(f\"Task {name} started\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"Task {name} completed after {delay} seconds\")\n",
    "\n",
    "\n",
    "# 获取事件循环\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# 创建任务\n",
    "task1 = loop.create_task(task(\"A\", 2))\n",
    "task2 = loop.create_task(task(\"B\", 1))\n",
    "\n",
    "# 等待任务完成\n",
    "loop.run_until_complete(asyncio.gather(task1, task2))\n",
    "\n",
    "# 关闭事件循环\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def infinite_task():\n",
    "    while True:\n",
    "        print(\"Running forever...\")\n",
    "\n",
    "\n",
    "# 获取事件循环\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# 创建任务\n",
    "task = loop.create_task(infinite_task())\n",
    "\n",
    "# 运行 3 秒后停止事件循环\n",
    "loop.call_later(3, loop.stop)\n",
    "\n",
    "# 启动事件循环\n",
    "loop.run_forever()\n",
    "\n",
    "# 关闭事件循环\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267697ed",
   "metadata": {},
   "source": [
    "##### Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b29d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "# 生产者协程\n",
    "async def producer(queue):\n",
    "    for i in range(5):\n",
    "        print(f\"Producer: producing {i}\")\n",
    "        await queue.put(i)  # 将数据放入队列\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "\n",
    "# 消费者协程\n",
    "async def consumer(queue):\n",
    "    while True:\n",
    "        item = await queue.get()  # 从队列中取出数据\n",
    "        if item is None:  # 如果是 None，说明生产者已结束，退出消费者\n",
    "            break\n",
    "        print(f\"Consumer: consumed {item}\")\n",
    "        queue.task_done()  # 标记任务完成\n",
    "        await asyncio.sleep(2)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # 创建一个容量为 3 的队列\n",
    "    queue = asyncio.Queue(maxsize=3)\n",
    "\n",
    "    # 创建生产者和消费者任务\n",
    "    producer_task = asyncio.create_task(producer(queue))\n",
    "    consumer_task = asyncio.create_task(consumer(queue))\n",
    "\n",
    "    # 等待生产者完成\n",
    "    await producer_task\n",
    "    # 向消费者发送停止信号（None）\n",
    "    await queue.put(None)\n",
    "    # 等待消费者完成\n",
    "    await consumer_task\n",
    "\n",
    "\n",
    "# 启动事件循环并执行 main 协程\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807c85d",
   "metadata": {},
   "source": [
    "##### Other\n",
    "\n",
    "- `asyncio.Barrier()`\n",
    "- `asyncio.Condition()`\n",
    "- `asyncio.Semaphore()`\n",
    "- `asyncio.BoundedSemaphore()`\n",
    "- `asyncio.Lock()`\n",
    "- `asyncio.RLock()`\n",
    "- `asyncio.Event()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b2789",
   "metadata": {},
   "source": [
    "#### [celery](https://docs.celeryq.dev)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4f75c",
   "metadata": {},
   "source": [
    "##### work\n",
    "\n",
    "- 假如当前为 `work.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "\n",
    "app = Celery(\n",
    "    \"tasks\",\n",
    "    broker=\"redis://43.156.74.18:6379/0\",\n",
    "    backend=\"redis://43.156.74.18:6379/0\",\n",
    ")\n",
    "\n",
    "\n",
    "@app.task\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0910b9",
   "metadata": {},
   "source": [
    "##### job\n",
    "\n",
    "- 当前是 `job.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from work import add\n",
    "\n",
    "result = add.apply_async((4, 6))\n",
    "print(\"Task ID:\", result.id)\n",
    "print(\"Result:\", result.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba53f3",
   "metadata": {},
   "source": [
    "##### work/job 必须要分开\n",
    "\n",
    "- work 进程启动的时候，它要只负责监听任务，不应该执行任务\n",
    "- producer（你写的提交任务的逻辑）应该是单独运行的进程，去 `apply_async()` 提交任务到队列。\n",
    "- 放在一起会阻塞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeecfaee",
   "metadata": {},
   "source": [
    "#### [ray](https://www.ray.io)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53494570",
   "metadata": {},
   "source": [
    "##### cluster\n",
    "\n",
    "```zsh\n",
    "# 主节点运行\n",
    "ray start --head --port=6379\n",
    "\n",
    "# 工作节点连接到主节点\n",
    "ray start --address='192.168.1.100:6379'\n",
    "ray start --address='192.168.1.100:6379' --redis-password='5241590000000000'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b8583",
   "metadata": {},
   "source": [
    "##### sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "ray.init()\n",
    "# ray.init(address=\"192.168.1.100:6379\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def multiply(x):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "futures = [multiply.remote(i) for i in range(100)]\n",
    "results = ray.get(futures)\n",
    "print(results)\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07941e8b",
   "metadata": {},
   "source": [
    "#### [dask](https://www.dask.org)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f691f1e",
   "metadata": {},
   "source": [
    "##### local cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7b5607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:51842' processes=4 threads=4, memory=24.00 GiB>\n",
      "Delayed('sum_list-9205217b-d908-4400-aa96-6a90a5ebbfdd')\n",
      "Result: 41\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# 先启动本地集群（4个 worker，每个 worker 1线程）\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "\n",
    "# 打印一下当前连接状态\n",
    "print(client)\n",
    "\n",
    "\n",
    "# 普通函数\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def sum_list(numbers):\n",
    "    return sum(numbers)\n",
    "\n",
    "\n",
    "# 用 delayed 包装（告诉 Dask 这些可以并行）\n",
    "a = delayed(add)(1, 2)\n",
    "b = delayed(multiply)(a, 10)\n",
    "c = delayed(sum_list)([b, 5, 6])\n",
    "\n",
    "# 构建好执行图，但到这里都还没真正执行\n",
    "print(c)  # 你会看到一个 delayed 对象\n",
    "\n",
    "# 真正执行（通过本地分布式集群）\n",
    "result = c.compute()\n",
    "\n",
    "print(\"Result:\", result)\n",
    "\n",
    "# 关闭 client（可选）\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa555187",
   "metadata": {},
   "source": [
    "##### remote\n",
    "\n",
    "|角色|IP地址|\n",
    "|---|---|\n",
    "|Scheduler|192.168.1.10|\n",
    "|Worker 1|192.168.1.11|\n",
    "|Worker 2|192.168.1.12|\n",
    "\n",
    "##### 搭建集群\n",
    "\n",
    "```zsh\n",
    "# scheduler, display: \"Scheduler at: tcp://192.168.1.10:8786\"\n",
    "dask-scheduler\n",
    "\n",
    "# worker 1/worker 2\n",
    "dask-worker tcp://192.168.1.10:8786\n",
    "```\n",
    "\n",
    "##### 代码连接集群\n",
    "\n",
    "```python\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client('tcp://192.168.1.10:8786')\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02decfb2",
   "metadata": {},
   "source": [
    "#### [dramatiq](https://dramatiq.io)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424bf28",
   "metadata": {},
   "source": [
    "##### work\n",
    "\n",
    "- 建立 `work.py` 文件，定义了 `add()` 方法\n",
    "- 执行 `dramatiq work`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dramatiq\n",
    "from dramatiq.brokers.redis import RedisBroker\n",
    "\n",
    "# 配置 Redis 作为 broker（默认连接 redis://localhost:6379/0）\n",
    "redis_broker = RedisBroker(url=\"redis://43.156.74.18:6379/0\")\n",
    "dramatiq.set_broker(redis_broker)\n",
    "\n",
    "\n",
    "@dramatiq.actor\n",
    "def add(x, y):\n",
    "    print(f\"Result: {x + y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b233fc7",
   "metadata": {},
   "source": [
    "##### job\n",
    "\n",
    "- 创建 `job.py` 文件\n",
    "- 调用方法并运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6465ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from work import add\n",
    "\n",
    "# 异步发送任务到 Dramatiq\n",
    "add.send(3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e04f6e",
   "metadata": {},
   "source": [
    "#### [arq](https://arq-docs.helpmanual.io)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f136b",
   "metadata": {},
   "source": [
    "##### work\n",
    "\n",
    "- `work.py` 文件，定义 `add()` 方法\n",
    "- 远程连接配置需要和 `job.py` 相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38134f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker.py\n",
    "from arq import func\n",
    "from arq.connections import RedisSettings\n",
    "\n",
    "\n",
    "async def add(ctx, a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "class WorkerSettings:\n",
    "    functions = [add]\n",
    "    redis_settings = RedisSettings(host=\"43.156.74.18\", port=6379, database=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810b71a",
   "metadata": {},
   "source": [
    "##### job\n",
    "\n",
    "- `job.py` 文件，调用 `add()` 方法\n",
    "- 远程连接配置需要和 `work.py` 相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e67414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from arq import create_pool\n",
    "from arq.connections import RedisSettings\n",
    "\n",
    "\n",
    "async def main():\n",
    "    redis = await create_pool(RedisSettings(host=\"43.156.74.18\", port=6379, database=0))\n",
    "    job = await redis.enqueue_job(\"add\", 3, 7)\n",
    "    result = await job.result(timeout=5)  # 等待任务完成并获取结果\n",
    "    print(f\"Got result: {result}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a31509",
   "metadata": {},
   "source": [
    "#### conclusion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cfd63",
   "metadata": {},
   "source": [
    "##### About Queue\n",
    "\n",
    "- `queue.Queue()` 是线程队列\n",
    "- `multiprocessing.Queue()` 是进程间队列\n",
    "- `multiprocessing.SimpleQueue()` 是进程间的简单队列\n",
    "- `mutliprocessing.Manager().Queue()` 是进程间共享队列\n",
    "- `asyncio.Queue()` 协程队列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32738ca0",
   "metadata": {},
   "source": [
    "##### 进程/线程/协程\n",
    "\n",
    "| **技术** | **资源开销** | **并行能力** | **适用场景**       | **典型用例**        |\n",
    "| ------ | -------- | -------- | -------------- | --------------- |\n",
    "| **进程** | 高        | 是（多核）    | CPU 密集型、隔离性要求高 | 视频编码、科学计算       |\n",
    "| **线程** | 中        | 否（受 GIL） | I/O 密集型、简单数据共享 | 数据库查询、GUI 事件处理  |\n",
    "| **协程** | 极低       | 否        | 超高并发 I/O、低延迟需求 | Web 服务器、爬虫、聊天服务 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c95b5",
   "metadata": {},
   "source": [
    "##### 线程/协程（协程为主，线程为辅）\n",
    "\n",
    "|**维度**|**线程（Thread）**|**协程（Coroutine）**|\n",
    "|---|---|---|\n",
    "|**调度机制**|由操作系统内核调度，抢占式（可能被强制切换）|用户态协作式调度（需主动 `yield`/`await`）|\n",
    "|**切换开销**|高（需内核态/用户态切换，保存寄存器等）|极低（通常只是函数调用级别的上下文保存）|\n",
    "|**内存占用**|每个线程需分配 MB 级栈内存（默认 1-8MB）|协程栈通常为 KB 级（甚至动态增长）|\n",
    "|**并行能力**|受限于 GIL（如 CPython），多核利用率低|单线程内并发，无法利用多核|\n",
    "|**编程复杂度**|需处理竞态条件（锁、信号量等）|无锁编程（但需避免阻塞操作）|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb37ca",
   "metadata": {},
   "source": [
    "##### celery/ray/dask\n",
    "\n",
    "\n",
    "| 框架         | 适合场景                               | 核心特点                                       |\n",
    "| ---------- | ---------------------------------- | ------------------------------------------ |\n",
    "| **Celery** | 异步任务队列（比如发送邮件、处理视频转码）              | 分布式任务调度，简单耐用，但主要是 I/O 型任务（不是很强调 CPU 密集计算）       |\n",
    "| **Ray**    | 分布式计算（高性能机器学习、大规模 Python 函数调度）       | 支持超大规模分布式、远超 Celery 性能，超简单的远程函数（@ray.remote） |\n",
    "| **Dask**   | 分布式数据处理（特别适合 Pandas、Numpy 那种表格/数组运算） | 并行化大数据处理（局部任务调度 + 延迟计算），轻量版的 Spark            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59226e",
   "metadata": {},
   "source": [
    "##### dramatiq/arq\n",
    "\n",
    "| 框架           | 适合什么情况                | 特点                            |\n",
    "| ------------ | --------------------- | ----------------------------- |\n",
    "| **dramatiq** | 想要比 Celery 更简单的同步任务队列   | 类似 Celery 但更优雅，支持 RabbitMQ/Redis |\n",
    "| **arq**      | asyncio 项目里需要高性能异步任务队列 | 完全 async/await，超轻量，只用 Redis    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
